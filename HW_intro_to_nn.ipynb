{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbLHTNfSclli"
      },
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtOYB-RHfc_r"
      },
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "KjoeaDrk6fO7"
      },
      "outputs": [],
      "source": [
        "t_inputs = torch.from_numpy(inputs)\n",
        "t_targets = torch.from_numpy(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKzbJKfOgGV8"
      },
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "aXhKw6Tdj1-d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x129072510>"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.random.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "eApcB7eb6h9o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True),\n",
              " tensor([0.6213], requires_grad=True))"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(1, 3, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGxNGTaf5s6"
      },
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "outputs": [],
      "source": [
        "def model(t_inputs, w, b):\n",
        "    z = t_inputs@torch.t(w) + b\n",
        "    return 1/(1+torch.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "predicted_probs = model(t_inputs, w, b)\n",
        "print(predicted_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На рандомних значеннях w та b результат кожного рядочка дуже близький до 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      },
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "outputs": [],
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "    log1 = true_labels*torch.log(predicted_probs)\n",
        "    log2 = (1-true_labels)*torch.log(1-predicted_probs)\n",
        "    entropies = -(log1 + log2)\n",
        "    return torch.mean(entropies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = binary_cross_entropy(predicted_probs, t_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFKpQxdHi1__"
      },
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "YAbXUNSJ6mCl"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[nan, nan, nan]])\n",
            "tensor([nan])\n"
          ]
        }
      ],
      "source": [
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDN1t1RujQsK"
      },
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOPSQyttpVjO"
      },
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "-JwXiSpX6orh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[6.6135e-04, 2.6692e-04, 6.1677e-05]], requires_grad=True),\n",
              " tensor([0.0006], requires_grad=True))"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "predicted_probs = model(t_inputs, w, b)\n",
        "print(predicted_probs)\n",
        "loss = binary_cross_entropy(predicted_probs, t_targets)\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -5.4417, -18.9853, -10.0682]]) tensor([-0.0794])\n"
          ]
        }
      ],
      "source": [
        "print(w.grad, b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCdi44IT334o"
      },
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "mObHPyE06qsO"
      },
      "outputs": [],
      "source": [
        "def grad_desc(inputs, targets,  model, w, b, alpha, epochs):\n",
        "    epoch = 0\n",
        "    loss_threshold = 0.03\n",
        "    loss_item = float('inf')\n",
        "    while epoch < epochs and loss_item > loss_threshold:\n",
        "        predicted_probs = model(inputs, w, b)\n",
        "        loss = binary_cross_entropy(predicted_probs, targets)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            w -= w.grad * alpha\n",
        "            b -= b.grad * alpha\n",
        "            w.grad.zero_()\n",
        "            b.grad.zero_()\n",
        "        epoch += 1\n",
        "        loss_item = loss.item()\n",
        "        if epoch % 100 == 0:\n",
        "            print(f'Epoch {epoch}, loss = {loss.item()}')\n",
        "        \n",
        "    print(f'Final loss:{loss.item()}')\n",
        "    return {'w': w, 'b': b}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100, loss = 0.03297306224703789\n",
            "Epoch 200, loss = 0.03153730183839798\n",
            "Epoch 300, loss = 0.03021698258817196\n",
            "Final loss:0.029990550130605698\n"
          ]
        }
      ],
      "source": [
        "epochs = 1000\n",
        "alpha = 1e-3\n",
        "params = grad_desc(t_inputs, t_targets, model, w, b, alpha, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[-0.4359252154827118, 0.1179201751947403, 0.5006595253944397]]"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params['w'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final values are \n",
            "weights : [[-0.4359252154827118, 0.1179201751947403, 0.5006595253944397]], \n",
            "bias : -0.02110949717462063\n"
          ]
        }
      ],
      "source": [
        "print(f'Final values are \\nweights : {params[\"w\"].tolist()}, \\nbias : {params[\"b\"].item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Запустила градієнтний спуск кілька разів, вважаю, що отримала мінімальне значення loss 0.02 (далі воно провалюється в nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuRhlyF9qAia"
      },
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X2dV30KtAPu"
      },
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "chrvMfBs6vjo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([73., 67., 43.]), tensor([0.]))\n",
            "(tensor([91., 88., 64.]), tensor([1.]))\n",
            "(tensor([ 87., 134.,  58.]), tensor([1.]))\n"
          ]
        }
      ],
      "source": [
        "t_inputs = torch.from_numpy(inputs)\n",
        "t_targets = torch.from_numpy(targets)\n",
        "train_ds = TensorDataset(t_inputs, t_targets)\n",
        "for i in range(3):\n",
        "    print(train_ds[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nMFaa8suOd3"
      },
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZCsRo5Mx6wEI"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymcQOo_hum6I"
      },
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "outputs": [],
      "source": [
        "class LogReg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(3, 5)\n",
        "        self.act1 = nn.Sigmoid()\n",
        "        self.linear2 = nn.Linear(5, 1)\n",
        "        self.act2 = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.act2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogReg()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RflV7xeVyoJy"
      },
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3QCATPU_6yfa"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), 1e-2)\n",
        "loss_fn = F.binary_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = model(t_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'targets': t_targets.tolist(), 'predictions': preds.tolist()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6420103907585144]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6420103907585144]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.6420103907585144]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.6540874242782593]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   targets           predictions\n",
              "0    [0.0]  [0.6540874242782593]\n",
              "1    [1.0]  [0.6540874242782593]\n",
              "2    [1.0]  [0.6540874242782593]\n",
              "3    [0.0]  [0.6420103907585144]\n",
              "4    [1.0]  [0.6540874242782593]\n",
              "5    [0.0]  [0.6540874242782593]\n",
              "6    [1.0]  [0.6540874242782593]\n",
              "7    [1.0]  [0.6540874242782593]\n",
              "8    [0.0]  [0.6420103907585144]\n",
              "9    [1.0]  [0.6540874242782593]\n",
              "10   [0.0]  [0.6540874242782593]\n",
              "11   [1.0]  [0.6540874242782593]\n",
              "12   [1.0]  [0.6540874242782593]\n",
              "13   [0.0]  [0.6420103907585144]\n",
              "14   [1.0]  [0.6540874242782593]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_data = loss_fn(preds, t_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6724725961685181\n"
          ]
        }
      ],
      "source": [
        "print(loss_data.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На мою думку, модель не навчилася"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch-WrYnKzMzq"
      },
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "cEHQH9qE626k"
      },
      "outputs": [],
      "source": [
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ініціалізуємо акумулятор для втрат\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            # Генеруємо передбачення\n",
        "            pred = model(xb)\n",
        "\n",
        "            # Обчислюємо втрати\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконуємо градієнтний спуск\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Накопичуємо втрати\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Обчислюємо середні втрати для епохи\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Виводимо підсумок епохи\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return {'losses': losses, 'model': model}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/1000], Loss: 0.6501\n",
            "Epoch [20/1000], Loss: 0.6415\n",
            "Epoch [30/1000], Loss: 0.6369\n",
            "Epoch [40/1000], Loss: 0.6319\n",
            "Epoch [50/1000], Loss: 0.6287\n",
            "Epoch [60/1000], Loss: 0.6232\n",
            "Epoch [70/1000], Loss: 0.6201\n",
            "Epoch [80/1000], Loss: 0.6155\n",
            "Epoch [90/1000], Loss: 0.6108\n",
            "Epoch [100/1000], Loss: 0.6068\n",
            "Epoch [110/1000], Loss: 0.6026\n",
            "Epoch [120/1000], Loss: 0.5994\n",
            "Epoch [130/1000], Loss: 0.5955\n",
            "Epoch [140/1000], Loss: 0.5921\n",
            "Epoch [150/1000], Loss: 0.5892\n",
            "Epoch [160/1000], Loss: 0.5860\n",
            "Epoch [170/1000], Loss: 0.5825\n",
            "Epoch [180/1000], Loss: 0.5796\n",
            "Epoch [190/1000], Loss: 0.5771\n",
            "Epoch [200/1000], Loss: 0.5748\n",
            "Epoch [210/1000], Loss: 0.5712\n",
            "Epoch [220/1000], Loss: 0.5686\n",
            "Epoch [230/1000], Loss: 0.5661\n",
            "Epoch [240/1000], Loss: 0.5650\n",
            "Epoch [250/1000], Loss: 0.5615\n",
            "Epoch [260/1000], Loss: 0.5592\n",
            "Epoch [270/1000], Loss: 0.5565\n",
            "Epoch [280/1000], Loss: 0.5547\n",
            "Epoch [290/1000], Loss: 0.5533\n",
            "Epoch [300/1000], Loss: 0.5516\n",
            "Epoch [310/1000], Loss: 0.5482\n",
            "Epoch [320/1000], Loss: 0.5474\n",
            "Epoch [330/1000], Loss: 0.5444\n",
            "Epoch [340/1000], Loss: 0.5437\n",
            "Epoch [350/1000], Loss: 0.5412\n",
            "Epoch [360/1000], Loss: 0.5402\n",
            "Epoch [370/1000], Loss: 0.5375\n",
            "Epoch [380/1000], Loss: 0.5359\n",
            "Epoch [390/1000], Loss: 0.5341\n",
            "Epoch [400/1000], Loss: 0.5338\n",
            "Epoch [410/1000], Loss: 0.5318\n",
            "Epoch [420/1000], Loss: 0.5304\n",
            "Epoch [430/1000], Loss: 0.5305\n",
            "Epoch [440/1000], Loss: 0.5284\n",
            "Epoch [450/1000], Loss: 0.5258\n",
            "Epoch [460/1000], Loss: 0.5250\n",
            "Epoch [470/1000], Loss: 0.5236\n",
            "Epoch [480/1000], Loss: 0.5221\n",
            "Epoch [490/1000], Loss: 0.5218\n",
            "Epoch [500/1000], Loss: 0.5195\n",
            "Epoch [510/1000], Loss: 0.5195\n",
            "Epoch [520/1000], Loss: 0.5174\n",
            "Epoch [530/1000], Loss: 0.5175\n",
            "Epoch [540/1000], Loss: 0.5154\n",
            "Epoch [550/1000], Loss: 0.5153\n",
            "Epoch [560/1000], Loss: 0.5133\n",
            "Epoch [570/1000], Loss: 0.5127\n",
            "Epoch [580/1000], Loss: 0.5114\n",
            "Epoch [590/1000], Loss: 0.5109\n",
            "Epoch [600/1000], Loss: 0.5115\n",
            "Epoch [610/1000], Loss: 0.5093\n",
            "Epoch [620/1000], Loss: 0.5082\n",
            "Epoch [630/1000], Loss: 0.5071\n",
            "Epoch [640/1000], Loss: 0.5068\n",
            "Epoch [650/1000], Loss: 0.5060\n",
            "Epoch [660/1000], Loss: 0.5051\n",
            "Epoch [670/1000], Loss: 0.5049\n",
            "Epoch [680/1000], Loss: 0.5032\n",
            "Epoch [690/1000], Loss: 0.5030\n",
            "Epoch [700/1000], Loss: 0.5023\n",
            "Epoch [710/1000], Loss: 0.5011\n",
            "Epoch [720/1000], Loss: 0.5005\n",
            "Epoch [730/1000], Loss: 0.5003\n",
            "Epoch [740/1000], Loss: 0.4996\n",
            "Epoch [750/1000], Loss: 0.4994\n",
            "Epoch [760/1000], Loss: 0.4982\n",
            "Epoch [770/1000], Loss: 0.4973\n",
            "Epoch [780/1000], Loss: 0.4966\n",
            "Epoch [790/1000], Loss: 0.4964\n",
            "Epoch [800/1000], Loss: 0.4955\n",
            "Epoch [810/1000], Loss: 0.4955\n",
            "Epoch [820/1000], Loss: 0.4953\n",
            "Epoch [830/1000], Loss: 0.4938\n",
            "Epoch [840/1000], Loss: 0.4933\n",
            "Epoch [850/1000], Loss: 0.4934\n",
            "Epoch [860/1000], Loss: 0.4943\n",
            "Epoch [870/1000], Loss: 0.4922\n",
            "Epoch [880/1000], Loss: 0.4913\n",
            "Epoch [890/1000], Loss: 0.4913\n",
            "Epoch [900/1000], Loss: 0.4904\n",
            "Epoch [910/1000], Loss: 0.4911\n",
            "Epoch [920/1000], Loss: 0.4897\n",
            "Epoch [930/1000], Loss: 0.4894\n",
            "Epoch [940/1000], Loss: 0.4887\n",
            "Epoch [950/1000], Loss: 0.4894\n",
            "Epoch [960/1000], Loss: 0.4877\n",
            "Epoch [970/1000], Loss: 0.4880\n",
            "Epoch [980/1000], Loss: 0.4871\n",
            "Epoch [990/1000], Loss: 0.4870\n",
            "Epoch [1000/1000], Loss: 0.4863\n"
          ]
        }
      ],
      "source": [
        "loss = fit_return_loss(1000, model, loss_fn, optimizer, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "fitted_model = loss['model']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.7243790626525879]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7234110236167908]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.725604772567749]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.161299929022789]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7255984544754028]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.7243790626525879]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7234110236167908]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.725604772567749]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.161299929022789]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7255984544754028]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.7243790626525879]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7234110236167908]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.725604772567749]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.161299929022789]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[0.7255984544754028]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   targets           predictions\n",
              "0    [0.0]  [0.7243790626525879]\n",
              "1    [1.0]  [0.7234110236167908]\n",
              "2    [1.0]   [0.725604772567749]\n",
              "3    [0.0]   [0.161299929022789]\n",
              "4    [1.0]  [0.7255984544754028]\n",
              "5    [0.0]  [0.7243790626525879]\n",
              "6    [1.0]  [0.7234110236167908]\n",
              "7    [1.0]   [0.725604772567749]\n",
              "8    [0.0]   [0.161299929022789]\n",
              "9    [1.0]  [0.7255984544754028]\n",
              "10   [0.0]  [0.7243790626525879]\n",
              "11   [1.0]  [0.7234110236167908]\n",
              "12   [1.0]   [0.725604772567749]\n",
              "13   [0.0]   [0.161299929022789]\n",
              "14   [1.0]  [0.7255984544754028]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_preds = fitted_model(t_inputs)\n",
        "dff = pd.DataFrame({'targets': t_targets.tolist(), 'predictions': final_preds.tolist()})\n",
        "dff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Лосс зменшується, але модель для всіх рядків видає дуже схожі прогнози, що ніяк не дає різницю для класифікації 0 чи 1("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZUklEQVR4nO3deVwV5f4H8M9ZOIdFNkEOiwi444aGiribFC6/q6V1zWtpZlqGpXIr5Zpamkt5K283yyVNS03La2pqmOKSJoqC4oYgIiDLYRFZZT1nfn9QY4dFEYE5wOf9ep3Xi3nmmTnfmVI+zjzzjEwQBAFEREREJJJLXQARERGRsWFAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCpdQFNFZ6vR4pKSmwtLSETCaTuhwiIiKqAUEQkJeXB2dnZ8jl1V8nYkCqpZSUFLi6ukpdBhEREdXC7du30bp162rXMyDVkqWlJYDyE2xlZSVxNURERFQTubm5cHV1FX+PV4cBqZb+vK1mZWXFgERERNTIPGx4DAdpExEREVXAgERERERUgeQBac2aNXB3d4epqSl8fHwQFhb2wP7Z2dkICAiAk5MT1Go1OnbsiIMHD4rr3d3dIZPJKn0CAgLEPkOHDq20/vXXX6+3YyQiIqLGRdIxSDt37kRgYCDWrl0LHx8frF69Gv7+/oiOjoaDg0Ol/iUlJXjqqafg4OCAXbt2wcXFBQkJCbCxsRH7nDt3DjqdTly+cuUKnnrqKTz//PMG+5o+fTqWLFkiLpubm9f9ARIREVGjJGlA+vTTTzF9+nRMnToVALB27VocOHAAmzZtwvz58yv137RpE7KysnD69GmYmJgAKL9i9FetWrUyWF65ciXatWuHIUOGGLSbm5vD0dGxDo+GiIiImgrJbrGVlJQgPDwcfn5+94uRy+Hn54fQ0NAqt9m3bx98fX0REBAAjUaDbt26Yfny5QZXjCp+x9atW/HKK69UGq2+bds22Nvbo1u3bggKCsK9e/ceWG9xcTFyc3MNPkRERNQ0SXYFKTMzEzqdDhqNxqBdo9Hg+vXrVW4TFxeHo0ePYtKkSTh48CBiY2PxxhtvoLS0FIsXL67Uf8+ePcjOzsbLL79s0P6Pf/wDbm5ucHZ2xqVLlzBv3jxER0dj9+7d1da7YsUKfPDBB49+oERERNToNKp5kPR6PRwcHLB+/XooFAp4e3sjOTkZq1atqjIgbdy4ESNHjoSzs7NB+4wZM8Sfu3fvDicnJwwfPhw3b95Eu3btqvzuoKAgBAYGist/TjRFRERETY9kAcne3h4KhQJpaWkG7WlpadWODXJycoKJiQkUCoXY5unpCa1Wi5KSEqhUKrE9ISEBR44ceeBVoT/5+PgAAGJjY6sNSGq1Gmq1+qH7IiIiosZPsjFIKpUK3t7eCAkJEdv0ej1CQkLg6+tb5TYDBgxAbGws9Hq92BYTEwMnJyeDcAQA33zzDRwcHDB69OiH1nLx4kUA5QGMiIiISNJ5kAIDA7FhwwZs2bIFUVFRmDlzJgoKCsSn2iZPnoygoCCx/8yZM5GVlYXZs2cjJiYGBw4cwPLlyw3mOALKg9Y333yDKVOmQKk0vEh28+ZNLF26FOHh4YiPj8e+ffswefJkDB48GD169Kj/gyYiIiKjJ+kYpAkTJiAjIwOLFi2CVqtFz549ERwcLA7cTkxMhFx+P8O5urri0KFDmDt3Lnr06AEXFxfMnj0b8+bNM9jvkSNHkJiYiFdeeaXSd6pUKhw5cgSrV69GQUEBXF1dMX78eLz33nv1e7BERETUaMgEQRCkLqIxys3NhbW1NXJycur0ZbVZBSUoKC6DrYUKLdSNagw9ERGR0avp72/JXzVCht76/gIGfXwMR66lPbwzERER1QsGJCOjVJRPaFmq0z+kJxEREdUXBiQjo/xjzFWZnnc+iYiIpMKAZGRMeAWJiIhIcgxIRsZEUf6fpFTHK0hERERSYUAyMn+OQSrjFSQiIiLJMCAZGROOQSIiIpIcA5KR4VNsRERE0mNAMjJ/jkEq4xgkIiIiyTAgGRml/I8rSHpeQSIiIpIKA5KRUfIKEhERkeQYkIwM50EiIiKSHgOSkeE8SERERNJjQDIynAeJiIhIegxIRobzIBEREUmPAcnIcB4kIiIi6TEgGRk+xUZERCQ9BiQjY/LHPEhlnAeJiIhIMgxIRubPK0glvIJEREQkGQYkI2PCp9iIiIgkx4BkZJRyjkEiIiKSGgOSkRFn0uYYJCIiIskwIBkZEz7FRkREJDkGJCPzZ0AqKeMVJCIiIqkwIBkZKzMlACC3qFTiSoiIiJovBiQjY2OmAgBk32NAIiIikgoDkpGxNjcBABSW6lBcppO4GiIiouaJAcnIWKqVkJU/yIacQl5FIiIikgIDkpGRy2WwNiu/ipTD22xERESSYEAyQjZ/BKS7DEhERESSYEAyQm3sLAAAl5NzJK6EiIioeWJAMkID29sBAJbuv4YrDElEREQNjgHJCD3Rxlb8eeKGMxJWQkRE1DwxIBkhTycr8ee8ojLo9XztCBERUUNiQDJCFmolhnd2EJfjMvMlrIaIiKj5kTwgrVmzBu7u7jA1NYWPjw/CwsIe2D87OxsBAQFwcnKCWq1Gx44dcfDgQXH9+++/D5lMZvDp3LmzwT6KiooQEBAAOzs7tGjRAuPHj0daWlq9HF9tbXy5D/q1bQkAOHsrS+JqiIiImhdJA9LOnTsRGBiIxYsXIyIiAl5eXvD390d6enqV/UtKSvDUU08hPj4eu3btQnR0NDZs2AAXFxeDfl27dkVqaqr4OXXqlMH6uXPn4ueff8aPP/6IEydOICUlBePGjau346ytge3tAQCbf4/nbTYiIqIGpJTyyz/99FNMnz4dU6dOBQCsXbsWBw4cwKZNmzB//vxK/Tdt2oSsrCycPn0aJiblcwW5u7tX6qdUKuHo6Fjld+bk5GDjxo3Yvn07nnzySQDAN998A09PT5w5cwb9+vWrcrvi4mIUFxeLy7m5uY90rLUxub871p6Iw430fJyJu4P+fwQmIiIiql+SXUEqKSlBeHg4/Pz87hcjl8PPzw+hoaFVbrNv3z74+voiICAAGo0G3bp1w/Lly6HTGb6z7MaNG3B2dkbbtm0xadIkJCYmiuvCw8NRWlpq8L2dO3dGmzZtqv1eAFixYgWsra3Fj6ura20PvcasTE3wfz2cAADBV7X1/n1ERERUTrKAlJmZCZ1OB41GY9Cu0Wig1VYdBuLi4rBr1y7odDocPHgQCxcuxCeffIIPP/xQ7OPj44PNmzcjODgYX331FW7duoVBgwYhLy8PAKDVaqFSqWBjY1Pj7wWAoKAg5OTkiJ/bt2/X8sgfzXDP8vNz9Ho6BIG32YiIiBqCpLfYHpVer4eDgwPWr18PhUIBb29vJCcnY9WqVVi8eDEAYOTIkWL/Hj16wMfHB25ubvjhhx8wbdq0Wn+3Wq2GWq1+7GN4VP3b2UGlkCPpbiFuZhSgvUOLBq+BiIiouZHsCpK9vT0UCkWlp8fS0tKqHT/k5OSEjh07QqFQiG2enp7QarUoKSmpchsbGxt07NgRsbGxAABHR0eUlJQgOzu7xt8rJQu1Ek+42QAAIhLuSlsMERFRMyFZQFKpVPD29kZISIjYptfrERISAl9f3yq3GTBgAGJjY6HX68W2mJgYODk5QaVSVblNfn4+bt68CSen8rE83t7eMDExMfje6OhoJCYmVvu9UuuksQQAvPu/S7zNRkRE1AAkfcw/MDAQGzZswJYtWxAVFYWZM2eioKBAfKpt8uTJCAoKEvvPnDkTWVlZmD17NmJiYnDgwAEsX74cAQEBYp+3334bJ06cQHx8PE6fPo1nn30WCoUCEydOBABYW1tj2rRpCAwMxLFjxxAeHo6pU6fC19e32ifYpOba0lz8OZxXkYiIiOqdpGOQJkyYgIyMDCxatAharRY9e/ZEcHCwOHA7MTERcvn9DOfq6opDhw5h7ty56NGjB1xcXDB79mzMmzdP7JOUlISJEyfizp07aNWqFQYOHIgzZ86gVatWYp/PPvsMcrkc48ePR3FxMfz9/fHll1823IE/okEdWgGIAgAk3LmH3u4tpS2IiIioiZMJvGdTK7m5ubC2tkZOTg6srKwevsFjmrIpDCdiMvCOfycEDGtf799HRETUFNX097fkrxqhmvFqbQ0ASM4ulLgSIiKipo8BqZFoY2cBALianCNxJURERE0fA1IjMaRjK8hkQGRSDpLu3pO6HCIioiaNAamRaGWpRt8/BmcP/OgY4jLyJa6IiIio6WJAakT+z8tZ/PmTX2MkrISIiKhpY0BqRMb8JSAduqrlgG0iIqJ6woDUiFibmWDJ2K4AgDK9gDH/PSVxRURERE0TA1Ij80QbW/HnOwUlOHApVcJqiIiImiYGpEamvUMLg+WA7RESVUJERNR0MSA1MqYmCrzj30nqMoiIiJo0BqRG6I2h7QyWC4rLJKqEiIioaWJAaoRkMhnm+nUUl+PvFEhYDRERUdPDgNRIzfbrAN+2dgCAuTsvSlsMERFRE8OA1Ih5u5U/0RaTlo/r2lyJqyEiImo6GJAasYk+bcSfR6w+iWmbz0lYDRERUdPBgNSIudiY4btpfcXlkOvpSLzDF9kSERE9LgakRm5Qh1Z43ru1uHwm7o6E1RARETUNDEhNwLJnu6OrsxUAIDGLV5CIiIgeFwNSE6BSyjG2Z/mLbL84FouBHx1FPudGIiIiqjUGpCaiTUtz8eeku4UIu8VbbURERLXFgNREDO7YymA5M69EokqIiIgaPwakJsJcpcQPr/mKy5xdm4iIqPYYkJqQvh4t8cGYrgCA/ZdSUVKml7giIiKixokBqYl5vndr2LdQIzHrHnZHJEldDhERUaPEgNTEmKuUeHWQBwBge1gidHpB4oqIiIgaHwakJuj/ejgBAC4l5eCZNb9LXA0REVHjw4DUBLW2NUcrSzUA4HJyDlKyCyWuiIiIqHFhQGqi1r/kLf78v3CORSIiInoUDEhNVK82tvhsghcA4OtTtzgWiYiI6BEwIDVhT3bWAAByCkuxeN8ViashIiJqPBiQmjBrMxP0aG0NANh6JhEvbTyLZI5HIiIieigGpCZu98z+cPhjwPbJG5lYuIdXkoiIiB6GAamJUyrk4uzaAPhEGxERUQ0wIDUDT3XRiD/nFJZKWAkREVHjIHlAWrNmDdzd3WFqagofHx+EhYU9sH92djYCAgLg5OQEtVqNjh074uDBg+L6FStWoE+fPrC0tISDgwOeeeYZREdHG+xj6NChkMlkBp/XX3+9Xo7PGCgVcvxvZn8AQGpOEfZfSpG4IiIiIuMmaUDauXMnAgMDsXjxYkRERMDLywv+/v5IT0+vsn9JSQmeeuopxMfHY9euXYiOjsaGDRvg4uIi9jlx4gQCAgJw5swZHD58GKWlpXj66adRUGD4dvvp06cjNTVV/Hz88cf1eqxS6+JkJf68/EAUikp1ElZDRERk3GSCIEg2QY6Pjw/69OmDL774AgCg1+vh6uqKN998E/Pnz6/Uf+3atVi1ahWuX78OExOTGn1HRkYGHBwccOLECQwePBhA+RWknj17YvXq1bWuPTc3F9bW1sjJyYGVldXDNzACRaU6DPv3caTmFGHeiM6YObSd1CURERE1qJr+/pbsClJJSQnCw8Ph5+d3vxi5HH5+fggNDa1ym3379sHX1xcBAQHQaDTo1q0bli9fDp2u+qshOTk5AICWLVsatG/btg329vbo1q0bgoKCcO/evQfWW1xcjNzcXINPY2NqosAcvw4AgL0XkyWuhoiIyHgppfrizMxM6HQ6aDQag3aNRoPr169XuU1cXByOHj2KSZMm4eDBg4iNjcUbb7yB0tJSLF68uFJ/vV6POXPmYMCAAejWrZvY/o9//ANubm5wdnbGpUuXMG/ePERHR2P37t3V1rtixQp88MEHtTxa4zGskwMAIDotD3cLSmBroZK4IiIiIuMjWUCqDb1eDwcHB6xfvx4KhQLe3t5ITk7GqlWrqgxIAQEBuHLlCk6dOmXQPmPGDPHn7t27w8nJCcOHD8fNmzfRrl3Vt52CgoIQGBgoLufm5sLV1bWOjqzhOFiZol0rC9zMKMC/f43Gsme7S10SERGR0ZHsFpu9vT0UCgXS0tIM2tPS0uDo6FjlNk5OTujYsSMUCoXY5unpCa1Wi5KSEoO+s2bNwv79+3Hs2DG0bt36gbX4+PgAAGJjY6vto1arYWVlZfBprJaOLb+atu1sIlYdqvpqHRERUXMmWUBSqVTw9vZGSEiI2KbX6xESEgJfX98qtxkwYABiY2Oh1+vFtpiYGDg5OUGlKr9VJAgCZs2ahZ9++glHjx6Fh4fHQ2u5ePEigPIA1hz0b2+P14eUXylbc+wmEu88ePwVERFRcyPpY/6BgYHYsGEDtmzZgqioKMycORMFBQWYOnUqAGDy5MkICgoS+8+cORNZWVmYPXs2YmJicODAASxfvhwBAQFin4CAAGzduhXbt2+HpaUltFottFotCgvLZ5C+efMmli5divDwcMTHx2Pfvn2YPHkyBg8ejB49ejTsCZDQ/JGd0dvNFgDwn5AbkPBhRiIiIqMj6RikCRMmICMjA4sWLYJWq0XPnj0RHBwsDtxOTEyEXH4/w7m6uuLQoUOYO3cuevToARcXF8yePRvz5s0T+3z11VcAyh/l/6tvvvkGL7/8MlQqFY4cOYLVq1ejoKAArq6uGD9+PN577736P2Aj88awdnhl83n8LyIJcZn58PGww7v+nSCXy6QujYiISFKSzoPUmDXGeZCqsuJgFNb9FicufzetLwZ1aCVhRURERPXH6OdBIuPw1vAOBsshUem83UZERM0eA1IzZ6FWYmLfNuLy5tPx2BfJd7UREVHzxoBEeH9MF4zsdn9qhWUHoiSshoiISHoMSAS1UoHPJvQUl52sTaUrhoiIyAgwIBGA8ve0ffK8FwAgMeseIhLvSlwRERGRdBiQSDSwgz0A4O69Uoz78jTOx2dJXBEREZE0GJBIpLEyhZ+ng7j83NpQTN4UhpIy/QO2IiIianoYkMjA0me6GSz/FpOBs7fuSFQNERGRNBiQyICTtRm+ntzboC3ydrY0xRAREUmEAYkqebKzAzo7WorLP0emSlgNERFRw2NAokrkchl+eN0X0wZ6AACi0/KQfa9E4qqIiIgaDgMSVcnK1AQL/68LHCzVAIDAHyJRVKqTuCoiIqKGwYBED9TCVAkAOHo9HT/zFSRERNRMMCDRA/V2sxV/vpaaK2ElREREDYcBiR5o1rAOsFApAADpucUSV0NERNQwGJDogdrYmWP1C70AlM+JlJ5XJHFFRERE9Y8BiR6qr0dL2JqbIK+4DJM3huFcfBbm7LgAbQ7DEhERNU0MSPRQ1mYm2Dy1L0wUMlzX5uH5taHYczEFyw5GSV0aERFRvWBAohrxcrXBv5/3MmiLy8iXqBoiIqL6xYBENTa2pwvmj+wsLtuYm0hYDRERUf1hQKJHMm2gB1TK8v9tikr1EldDRERUPxiQ6JGYKOTYMaMfACA84S7Ox2dJXBEREVHdY0CiR9bN2RpuduYAgFc2n4NeL0hcERERUd1iQKJHplLK8e0rfQEAuUVl+NdPlyWuiIiIqG4xIFGtuNlZYIqvGwDgwOVUvsiWiIiaFAYkqrXFf+sKFxsz5BWVYdb2CAgCb7UREVHTwIBEtSaXy/Dhs90AAEei0rHnYrLEFREREdUNBiR6LMM6OWDyH7faFu+9ylttRETUJDAg0WMLGumJFmolcovKMGFdKK4k50hdEhER0WNhQKLHZqZS4O+9XQEAkUk5mLPzIscjERFRo8aARHXitSFt4WRtCgCITc/HpSReRSIiosaLAYnqhMbKFKFBw/FsLxcAwLz/XUKprvxVJPdKypCeVyRleURERI+EAYnq1Nv+nWCuUuC6Ng/n4+8CAPw+OYG+y0IYkoiIqNFgQKI65WJjhqe6aAAA7+yKRFpuEVJyyoPR2Ti+t42IiBoHBiSqc9MHtUULtRJJdwvx4YEosV0pl0lYFRERUc1JHpDWrFkDd3d3mJqawsfHB2FhYQ/sn52djYCAADg5OUGtVqNjx444ePDgI+2zqKgIAQEBsLOzQ4sWLTB+/HikpaXV+bE1V91crLH2RW8AwM+RKWJ7yR9jkoiIiIydpAFp586dCAwMxOLFixEREQEvLy/4+/sjPT29yv4lJSV46qmnEB8fj127diE6OhobNmyAi4vLI+1z7ty5+Pnnn/Hjjz/ixIkTSElJwbhx4+r9eJuTAe3tMLhjK4O23MJSiaohIiJ6NDJBwglrfHx80KdPH3zxxRcAAL1eD1dXV7z55puYP39+pf5r167FqlWrcP36dZiYmNRqnzk5OWjVqhW2b9+O5557DgBw/fp1eHp6IjQ0FP369atR7bm5ubC2tkZOTg6srKxqc/hN3m8xGZi86f7Vu7ef7ohZT3aQsCIiImruavr7W7IrSCUlJQgPD4efn9/9YuRy+Pn5ITQ0tMpt9u3bB19fXwQEBECj0aBbt25Yvnw5dDpdjfcZHh6O0tJSgz6dO3dGmzZtqv1eACguLkZubq7Bhx5scMdW8HazFZdP37wjYTVEREQ1J1lAyszMhE6ng0ajMWjXaDTQarVVbhMXF4ddu3ZBp9Ph4MGDWLhwIT755BN8+OGHNd6nVquFSqWCjY1Njb8XAFasWAFra2vx4+rq+qiH3Cztet0XnR0tAZQHpHPxfJKNiIiMn+SDtB+FXq+Hg4MD1q9fD29vb0yYMAELFizA2rVr6/27g4KCkJOTI35u375d79/ZFMhkMnw9pbe4/PzaUKTmFEpYERER0cNJFpDs7e2hUCgqPT2WlpYGR0fHKrdxcnJCx44doVAoxDZPT09otVqUlJTUaJ+Ojo4oKSlBdnZ2jb8XANRqNaysrAw+VDOtbc2xJ2CAuPzN7/HSFUNERFQDkgUklUoFb29vhISEiG16vR4hISHw9fWtcpsBAwYgNjYWev39x8VjYmLg5OQElUpVo316e3vDxMTEoE90dDQSExOr/V56fD1dbcRH/9f/FodDV6u/nUlERCQ1SW+xBQYGYsOGDdiyZQuioqIwc+ZMFBQUYOrUqQCAyZMnIygoSOw/c+ZMZGVlYfbs2YiJicGBAwewfPlyBAQE1Hif1tbWmDZtGgIDA3Hs2DGEh4dj6tSp8PX1rfETbFQ7wzrff+z/te/CJayEiIjowZRSfvmECROQkZGBRYsWQavVomfPnggODhYHWScmJkIuv5/hXF1dcejQIcydOxc9evSAi4sLZs+ejXnz5tV4nwDw2WefQS6XY/z48SguLoa/vz++/PLLhjvwZkqtVOCfT3XEJ4djAAC7I5Iw7onWEldFRERUmaTzIDVmnAep9iauP4PQuPJH/kd1d4SZiRLvjfaErYVK4sqIiKipM/p5kKj52vhyb/HR/4OXtfhfRBIW7LkscVVERET3MSBRgzNXKfHJ370M2g5d5bvwiIjIeDAgkSS6OlvjvdGe4rJOL+D7sEQJKyIiIrqPAYkkM22gBza9fH8SyaDdlxGVyle4EBGR9BiQSDIymQxPdtZg4f91EduupTAgERGR9BiQSHLTBnpgaKfyOZL++WMkJq4/Az5cSUREUmJAIqPg53l/nqrQuDtIuHNPwmqIiKi5Y0AiozDuCReD5WGfHEduUalE1RARUXPHgERGwVylxPfT77/qRRCA70ITJKyIiIiaMwYkMhq+7ewQ/eEItFCXvwHnh/O3UarTI7+4DCVl+odsTUREVHf4qpFa4qtG6k9+cRmGfHwMdwpKAACWpkq421ng5zcHSlwZERE1dnzVCDVaLdRK/F8PJ3E5r6gMl5NzcK+kTMKqiIioOWFAIqP02pB2ldq0OUUSVEJERM0RAxIZJWcbM9xcPgrfvtJXbGNAIiKihsKAREZLIZdhcMdWGNDeDgCQdLdQ4oqIiKi5YEAio9fFqXwQ3bv/u4SO7/2CbWf5+D8REdUvBiQyetMHt4V9CzUAoKRMjwU/XZG4IiIiauoYkMjoOViaYt1LTxi05RfziTYiIqo/DEjUKHi7tcShOYPF5V3nb0tYDRERNXUMSNRodHK0xAdjugIAPgqOxo20PIkrIiKipooBiRqVF/u54Yk2Nigs1WHU5ycx/3+XkJFXLHVZRETUxNQqIN2+fRtJSUniclhYGObMmYP169fXWWFEVVHIZfhsQk900liiVCdgx7nb+OePkVKXRURETUytAtI//vEPHDt2DACg1Wrx1FNPISwsDAsWLMCSJUvqtECiitzsLHDgrfvvZfstJgN8pSAREdWlWgWkK1euoG/f8hmOf/jhB3Tr1g2nT5/Gtm3bsHnz5rqsj6hKSoUc/5vZX1w+n3BXwmqIiKipqVVAKi0thVpdPi/NkSNHMGbMGABA586dkZqaWnfVET2At5stxng5AwCeXxuKd3dF8koSERHViVoFpK5du2Lt2rU4efIkDh8+jBEjRgAAUlJSYGdnV6cFEj3Isme7wfOPmbZ/OJ+Er0/eQnhClsRVERFRY1ergPTRRx9h3bp1GDp0KCZOnAgvLy8AwL59+8Rbb0QNwdLUBLtn9oeZiQIAsOxgFMZ/FYrLSTkSV0ZERI2ZTKjlPQmdTofc3FzY2tqKbfHx8TA3N4eDg0OdFWiscnNzYW1tjZycHFhZWUldTrN3O+seBn18TFx+x78TAoa1l7AiIiIyRjX9/V2rK0iFhYUoLi4Ww1FCQgJWr16N6OjoZhGOyPi4tjTH8beHistXknOQU1iK32IyoNNzXBIRET2aWgWksWPH4ttvvwUAZGdnw8fHB5988gmeeeYZfPXVV3VaIFFNudtbYO2L5e9s++WKFl4f/IrJm8Kw/GCUxJUREVFjU6uAFBERgUGDBgEAdu3aBY1Gg4SEBHz77bf4/PPP67RAokfh39UR/9fDyaBt46lbfLqNiIgeSa0C0r1792BpaQkA+PXXXzFu3DjI5XL069cPCQkJdVog0aOQyWT49/NeeN67NVxszMR2vo6EiIgeRa0CUvv27bFnzx7cvn0bhw4dwtNPPw0ASE9P54BlkpypiQKrnvfC7/OfRFt7CwBAWDwf/SciopqrVUBatGgR3n77bbi7u6Nv377w9fUFUH41qVevXnVaINHj6N++fF6uWdsv4PC1NImrISKixqLWj/lrtVqkpqbCy8sLcnl5zgoLC4OVlRU6d+5cp0UaIz7m3zgk3rmH0Z+fRF5xGQAg/D0/3EjPx++xmZg9vAOUilr9G4GIiBqpen3MHwAcHR3Rq1cvpKSkICkpCQDQt2/fWoWjNWvWwN3dHaampvDx8UFYWFi1fTdv3gyZTGbwMTU1NehTcf2fn1WrVol93N3dK61fuXLlI9dOxq2NnTmOvzNUXF607ypeWH8G/z0ai90RydIVRkRERq1WAUmv12PJkiWwtraGm5sb3NzcYGNjg6VLl0Kv1z/Svnbu3InAwEAsXrwYERER8PLygr+/P9LT06vdxsrKCqmpqeKn4sDwv65LTU3Fpk2bIJPJMH78eIN+S5YsMej35ptvPlLt1DjYtVBjYl9XAMCBS/ffFRiXWSBVSUREZOSUtdlowYIF2LhxI1auXIkBAwYAAE6dOoX3338fRUVFWLZsWY339emnn2L69OmYOnUqAGDt2rU4cOAANm3ahPnz51e5jUwmg6OjY7X7rLhu7969GDZsGNq2bWvQbmlp+cD9/FVxcTGKi+8/CZWbm1uj7cg4LH+2O4pL9dh94f5Vo58jUzBvRCfIZDIJKyMiImNUqytIW7Zswddff42ZM2eiR48e6NGjB9544w1s2LABmzdvrvF+SkpKEB4eDj8/v/sFyeXw8/NDaGhotdvl5+fDzc0Nrq6uGDt2LK5evVpt37S0NBw4cADTpk2rtG7lypWws7NDr169sGrVKpSVlVW7nxUrVsDa2lr8uLq61vAoyRjIZDKsGN8dfp4asS05uxDfhnJaCiIiqqxWASkrK6vKsUadO3dGVlbNH6fOzMyETqeDRqMxaNdoNNBqtVVu06lTJ2zatAl79+7F1q1bodfr0b9/f3EcVEVbtmyBpaUlxo0bZ9D+1ltvYceOHTh27Bhee+01LF++HO+++261tQYFBSEnJ0f83L59u8bHScZBrVTg6ym9sf/NgWLbz5EpElZERETGqla32Ly8vPDFF19UmjX7iy++QI8ePeqksOr4+vqK0woAQP/+/eHp6Yl169Zh6dKllfpv2rQJkyZNqjSQOzAwUPy5R48eUKlUeO2117BixQqo1epK+1Gr1VW2U+PTzcUawXMGYcTqkzifcBcnb2RgUIdWUpdFRERGpFYB6eOPP8bo0aNx5MgRMayEhobi9u3bOHjwYI33Y29vD4VCgbQ0w/lp0tLSajw2yMTEBL169UJsbGyldSdPnkR0dDR27tz50P34+PigrKwM8fHx6NSpU80OgBqtThpLtGtlgZsZBXhpYxh2zugHn7Z2UpdFRERGola32IYMGYKYmBg8++yzyM7ORnZ2NsaNG4erV6/iu+++q/F+VCoVvL29ERISIrbp9XqEhIQYXCV6EJ1Oh8uXL8PJyanSuo0bN8Lb2xteXl4P3c/Fixchl8vh4OBQ4/qp8ZLJZPh2mo+4PGH9GUSlcuA9ERGVq/VEkVWJjIzEE088AZ1OV+Ntdu7ciSlTpmDdunXo27cvVq9ejR9++AHXr1+HRqPB5MmT4eLighUrVgAofzS/X79+aN++PbKzs7Fq1Srs2bMH4eHh6NKli7jf3NxcODk54ZNPPsHrr79u8J2hoaE4e/Yshg0bBktLS4SGhmLu3LkYOXIktmzZUqO6OVFk07Dx1C0s3X8NANDH3Raf/r0nXFuaS1wVERHVl5r+/q7VLba6NGHCBGRkZGDRokXQarXo2bMngoODxYHbiYmJ4kzdAHD37l1Mnz4dWq0Wtra28Pb2xunTpw3CEQDs2LEDgiBg4sSJlb5TrVZjx44deP/991FcXAwPDw/MnTvXYFwSNQ/TBnrAx6MlxnxxCufi72LQx8fw2uC2eLqrI7zdbKUuj4iIJCL5FaTGileQmpZvfr+FD36+ZtAW8+FIqJR8FQkRUVNS768aIWpKpg7wwLev9DVou5KSI1E1REQktUe6xVZxLqGKsrOzH6cWIkkN7tgKC/+vizgmad2Jm/h8Yi+olQqJKyMioob2SAHJ2tr6oesnT578WAURSemVAe6wNjPB2z9G4tDVNPx9bSg6O1ph5tB2cLe3kLo8IiJqIHU6Bqk54RikpksQBCw/GIUNJ2+JbV6uNtgbMEDCqoiIqC5wDBJRLclkMiwY3QXPe7cW2yJvZ2Pkf04iI6/4AVsSEVFTwYBEVI33x3TFoA724nJUai6Gf3Icnx2OAS+8EhE1bQxIRNWwUCuxZarhk225RWX4T8gN/HYjU6KqiIioITAgET2AXC5DzIcj0dJCZdA+bfM53m4jImrCGJCIHkKllCPsX8PxRBsbsa1ML6DPsiMo1emlK4yIiOoNAxJRDSgVcmyf3g8T+7oatM/ZeRFfHo/lmCQioiaGAYmohkxNFFj2THd0cbr/WOiBS6n4ODgaR6LSJayMiIjqGgMS0SOQy2U4OHsQPh7fw6D9akoO8opKJaqKiIjqGgMSUS0808sFQzq2EpdXH7mBPsuO4FJStnRFERFRnWFAIqoFlVKOLa/0xWcTvMS2olI9xnzxO1KyCyWsjIiI6gIDEtFjGOPlgo/H94BrSzOxrf/Ko5i94wKfcCMiasQYkIgeg0Iuw9/7uOLzF3oZtO+9mIKj1zlwm4iosWJAIqoDXq1t0LaVhUFbem6RRNUQEdHjYkAiqgNyuQyH5w7BGC9nse1mRoGEFRER0eOQCZzhrlZyc3NhbW2NnJwcWFlZPXwDajb2XkzG7B0XxeVWlmp8MKYrRnV3kq4oIiICUPPf37yCRFTHRnZzQkdNC3E5I68Yb2yLgF7Pf4sQETUWDEhEdUyllOPgW4OwYlx3g/bOC4NxIiYDwVdSMePb88i5x4kliYiMlVLqAoiaIqVCjol92+BaSi6+O5MAACjR6bH2+E2Ext0BALQ9cRPzR3aWskwiIqoGryAR1aNFf+uCoL+EoD/DEQCk8Sk3IiKjxYBEVI9MFHJMH9S20rvbAODg5VSGJCIiI8WARFTP5H9MJrn+JW+D9uIyPUZ/fgqFJTqJKiMiouowIBE1kKe7OuKj8YYDtzPzi3HxdjYS7hQgp5CDtomIjAUDElEDmtCnDSIXPw1na1Ox7fuwRAxZdRyvbjknYWVERPRXDEhEDczazASHA4dgiq8bAGBfZAoA4Fz8Xfxw7raUpRER0R8YkIgkYKFWImiUJwZ3bGXQ/u7/LiHydjZ0nFSSiEhSDEhEEjE1UeCbl/vgreEdDNrHrvkdnx2OQZlOL1FlRETEd7HVEt/FRnVJrxfwxIeHkf2X2bVVSjlOzRsGB0vTB2xJRESPgu9iI2pE5HIZvpj4BNq0NBfbSsr0eGHdGQmrIiJqvhiQiIzEwA72+O3dYVj74hNiW1xmAUrK9Cgu41xJREQNiQGJyMiM6OaE/W8OFJc7vvcLOr0XjJ8uJCHhToGElRERNR9GEZDWrFkDd3d3mJqawsfHB2FhYdX23bx5M2QymcHH1NRwjMbLL79cqc+IESMM+mRlZWHSpEmwsrKCjY0Npk2bhvz8/Ho5PqJH1c3FGuN6uRi0zd0ZiSGrjuNC4l2JqiIiaj4kD0g7d+5EYGAgFi9ejIiICHh5ecHf3x/p6enVbmNlZYXU1FTxk5CQUKnPiBEjDPp8//33BusnTZqEq1ev4vDhw9i/fz9+++03zJgxo86Pj6i2/jXaE2Ymikrtz355GoE7L0LPqQCIiOqN5AHp008/xfTp0zF16lR06dIFa9euhbm5OTZt2lTtNjKZDI6OjuJHo9FU6qNWqw362NraiuuioqIQHByMr7/+Gj4+Phg4cCD++9//YseOHUhJSamX4yR6VPYt1IhaOgILRnlWWrf7QjIuJmU3fFFERM2EpAGppKQE4eHh8PPzE9vkcjn8/PwQGhpa7Xb5+flwc3ODq6srxo4di6tXr1bqc/z4cTg4OKBTp06YOXMm7ty5I64LDQ2FjY0NevfuLbb5+flBLpfj7NmzVX5ncXExcnNzDT5EDWH64LZY/LculdqjtXk4E3cHnKmDiKjuSRqQMjMzodPpKl0B0mg00Gq1VW7TqVMnbNq0CXv37sXWrVuh1+vRv39/JCUliX1GjBiBb7/9FiEhIfjoo49w4sQJjBw5Ejpd+ZNAWq0WDg4OBvtVKpVo2bJltd+7YsUKWFtbix9XV9fHOXSiRzJ1gAeufOBv0Ba0+zJeWH8GwVeq/n+WiIhqT/JbbI/K19cXkydPRs+ePTFkyBDs3r0brVq1wrp168Q+L7zwAsaMGYPu3bvjmWeewf79+3Hu3DkcP3681t8bFBSEnJwc8XP7Nt+ZRQ2rhVqJE+8MrdS+JTQeeUWlyLlXiq9PxuF4dPXj94iIqGaUUn65vb09FAoF0tLSDNrT0tLg6OhYo32YmJigV69eiI2NrbZP27ZtYW9vj9jYWAwfPhyOjo6VBoGXlZUhKyur2u9Vq9VQq9U1qomovrjZWeDWilHYfDoeH/x8DQBwJi4L3d//1aDfrRWjIJPJpCiRiKhJkPQKkkqlgre3N0JCQsQ2vV6PkJAQ+Pr61mgfOp0Oly9fhpOTU7V9kpKScOfOHbGPr68vsrOzER4eLvY5evQo9Ho9fHx8ank0RA1DJpNh6gAPHJ47uNo+SXcLG7AiIqKmR/JbbIGBgdiwYQO2bNmCqKgozJw5EwUFBZg6dSoAYPLkyQgKChL7L1myBL/++ivi4uIQERGBF198EQkJCXj11VcBlA/gfuedd3DmzBnEx8cjJCQEY8eORfv27eHvXz6Gw9PTEyNGjMD06dMRFhaG33//HbNmzcILL7wAZ2fnhj8JRLXQQWOJiIVPVblu1OcnUVTK2beJiGpL8oA0YcIE/Pvf/8aiRYvQs2dPXLx4EcHBweLA7cTERKSmpor97969i+nTp8PT0xOjRo1Cbm4uTp8+jS5dyp/yUSgUuHTpEsaMGYOOHTti2rRp8Pb2xsmTJw1ukW3btg2dO3fG8OHDMWrUKAwcOBDr169v2IMnekwtLVQ4+e4wqJSGf5TzisrQeWEwriTnSFQZEVHjJhP4jHCt1PRtwEQNRacXsHT/NWw+HW/QvmCUJ/q1tUP31tbSFEZEZERq+vtb8itIRFQ3FHIZXvJ1q9S+7GAU/vbFKZy6kSlBVUREjRMDElET0q5VC0QufhoH3xpUad2LG8/ichJvuRER1QQDElETY21mAk8nSzzn3brSunFf/Y6C4jKU6vQSVEZE1HhwDFItcQwSNQax6Xn4x4azSM8rrrRu3BMu+Gh8D5go+O8kImo+OAaJiNDewRJhC/zwxtB2ldbtjkjG1jMJElRFRGT8GJCImoF3R3TGrRWjKrVHa/MkqIaIyPgxIBE1EzKZDN9M7WPQtjsiGd+FxqNUp0d6XpFElRERGR+OQaoljkGixkoQBHx3JgFrj99ESo5hKJri64YPxnaTqDIiovpX09/fDEi1xIBEjZ0gCJi1/QIOXE41aG+hVuJ/M/vD1twEDlamElVHRFQ/OEibiB5IJpPh3897oYNDC4P2/OIy+K/+DaP/ewr3Ssokqo6ISFoMSETNmJlKgcOBQ3Bj2Uh4u9karMvIK0aXRYeQU1gqUXVERNJhQCIimCjk2Dy1DwZ3bFVp3cT1Z3DoqlaCqoiIpMOAREQAAEtTE3z7Sl+8N9rToP1aai5e+y4cL6wPBYcsElFzwYBERAZeHdQW15eOgIlCZtB+Ji4LHkEHEZvOuZOIqOljQCKiSkxNFIj5cCQ+Ht+j0jq/T39D4M6LfJ8bETVpDEhEVCWZTIa/93HF2X8Nr7Ru94VkdFjwC07HZiLnXilm77iAsFtZElRJRFQ/OA9SLXEeJGpOikp1+Dg4Gpt+v2XQ3tbeAk+42WJXeBIAIH7laCnKIyKqMc6DRER1xtREgUV/64J1L3kbtMdlFojhCACCr2h5642ImgQGJCKqMf+ujrjygT/+O7FXletf3xqO5QejGrgqIqK6x4BERI+khVqJv3k549CcwVWu/+b3ePRfEYKCYs7CTUSNF8cg1RLHIBEBKdmFuJSUg+6trTFg5dFK68P+NZzvcyMio8IxSERU75xtzDCimyNcbMzw86yBldZ/8PM1TP/2PJKzCyWojoio9pRSF0BETUM3FyvM9esIpUKGVYeiAQAHLqcCACzVSgz31CD+TgHeGNoOMpkMZTo9lAr+G42IjBNvsdUSb7ERVS/7XgmGrDpe5YtuX+zXBhZqJbaGJmDvrIFo79BCggqJqLniLTYikoyNuQrfT++H4Z0dKq3beiYR607EoaBEh5W/8Ik3IjJODEhEVC+6OFth48t9sHpCz2r7xKbno7BE13BFERHVEG+x1RJvsRHVXKlOjx1hiQiLv4ufI1MM1qkUcmx8uTcGdWglUXVE1JzwFhsRGQ0ThRwv+brjvxN7YVwvF4N1JTo9XtoYhvjMAvwemwkAWHfiJr4PS5SiVCIiAHyKjYga2LJnu8PKzASbT8cbtA/993EAgIuNmTgtwLO9XGBqomjgComIeAWJiBqYmUqB98d0xZUP/LHquR6V1v91zqTbWfcasjQiIhEDEhFJooVaied7uyJy8dP4ZfYg9PVoWalPwh0GJCKSBgMSEUnK2swEnk5W2DG9H1pZqg3WvfrteXwcfB3u8w/Aff4BRN7Ohl4v4NerWmTfK5GoYiJqDhiQiMgoyOUy7Js1AK8NbmvQ/uXxm+LPi/ZdxXdnEjDju3C8uuV8Q5dIRM0IH/OvJT7mT1R/Ssr02H42Ae//fK3SuhZqJfKLywAAt1aMgkwma+jyiKgRq+nvbwakWmJAIqp/xWU6bD+biLTcYqw9cbPS+tnDO6CPe0sM7GAvQXVE1Bg1qnmQ1qxZA3d3d5iamsLHxwdhYWHV9t28eTNkMpnBx9TUVFxfWlqKefPmoXv37rCwsICzszMmT56MlBTDyenc3d0r7WflypX1doxE9OjUSgWmDvDAu/6dMKq7Y6X1/wm5gRc3nsXsHRckqI6ImjLJA9LOnTsRGBiIxYsXIyIiAl5eXvD390d6enq121hZWSE1NVX8JCQkiOvu3buHiIgILFy4EBEREdi9ezeio6MxZsyYSvtZsmSJwX7efPPNejlGIno8crkMX07yxol3huK1IW3xfz2cDNbvvZiCy0k5AIAynV6KEomoiZF8oshPP/0U06dPx9SpUwEAa9euxYEDB7Bp0ybMnz+/ym1kMhkcHSv/axIArK2tcfjwYYO2L774An379kViYiLatGkjtltaWla7n4qKi4tRXFwsLufm5tZoOyKqO252Fgga6YmSMj3yi8twPDpDXPe3L06JP/d2s8X26f2gUkr+b0AiaqQk/dujpKQE4eHh8PPzE9vkcjn8/PwQGhpa7Xb5+flwc3ODq6srxo4di6tXrz7we3JyciCTyWBjY2PQvnLlStjZ2aFXr15YtWoVysrKqt3HihUrYG1tLX5cXV1rdpBEVOdUSjk2T+2L+JWj0VHTotL68wl3EbT7sgSVEVFTIWlAyszMhE6ng0ajMWjXaDTQarVVbtOpUyds2rQJe/fuxdatW6HX69G/f38kJSVV2b+oqAjz5s3DxIkTDQZjvfXWW9ixYweOHTuG1157DcuXL8e7775bba1BQUHIyckRP7dv367FERNRXds4pQ9e7NcG7R0Mg9L/IpIwYOVRZOYXV7MlEVH1JH2KLSUlBS4uLjh9+jR8fX3F9nfffRcnTpzA2bNnH7qP0tJSeHp6YuLEiVi6dGmldePHj0dSUhKOHz/+wNHqmzZtwmuvvYb8/Hyo1epq+/2JT7ERGZ/CEh08FwVXah/R1RFrJj2BPReSMbhjq0oTUhJR89EonmKzt7eHQqFAWlqaQXtaWlqNxwaZmJigV69eiI2NNWgvLS3F3//+dyQkJODw4cMPDTE+Pj4oKytDfHz8Ix0DERkPM5UC15eOgMbKMAAFX9Wi3b8O4p8/RqLPsiN4dcs5lJTpodcLyCksxdcn45BTWCpR1URkjCQdpK1SqeDt7Y2QkBA888wzAAC9Xo+QkBDMmjWrRvvQ6XS4fPkyRo0aJbb9GY5u3LiBY8eOwc7O7qH7uXjxIuRyORwcHGp1LERkHExNFDj7Lz8kZxciIbMA//i68pXoI1Hp6PjeLwZt0do8rHreq6HKJCIjJ/kjHoGBgdiwYQO2bNmCqKgozJw5EwUFBeJTbZMnT0ZQUJDYf8mSJfj1118RFxeHiIgIvPjii0hISMCrr74KoDwcPffcczh//jy2bdsGnU4HrVYLrVaLkpLydzeFhoZi9erViIyMRFxcHLZt24a5c+fixRdfhK2tbcOfBCKqcy42Zujf3h7Xl47Ac96tH9o/+ErV4x6JqHmS/DH/CRMmICMjA4sWLYJWq0XPnj0RHBwsDtxOTEyEXH4/x929exfTp0+HVquFra0tvL29cfr0aXTp0gUAkJycjH379gEAevbsafBdx44dw9ChQ6FWq7Fjxw68//77KC4uhoeHB+bOnYvAwMCGOWgiajCmJgr8+3kvvD6kLf57NBa5haU49pfpAf7kaG1axdZE1FzxVSO1xEHaRI3XtZRcvLjxLLIKSgza173kjZ6uNtBYMSwRNVV8F1s9Y0AiavyOXEvD92GJCLluOHO/SiHHzKHtMHt4B8jlfBkuUVPCgFTPGJCImo4LiXfx/NpQlOkr/3X4jn8nHLiUiu4u1pgxpC3atao8MSURNR4MSPWMAYmoabmTX4yIxGzsuZiMA5dSq+xjbWaCcwv8+AoTokaMAameMSARNU2lOj1CotJxMyMfqw5FAwBaWaqRkXd/Ru6lz3RDm5bm+PRwDJaO7YoerW0kqpaIHhUDUj1jQCJq+nIKS/Hj+dsY3LEV5u68iKsplV9S3cpSjXML/KrYmoiMUaOYSZuIyJhZm5ng1UFt0VFjiaXPdKuyT0ZeMc7FZyFo92W8+PVZpOcWNXCVRFQfeAWplngFiah52nI6Hov3XX1gH283W7zj3wn92j58Fn8iali8xVbPGJCImrc7+cVIzi7EmC9+r7bPwbcGYdPvtzBrWHu421s0YHVEVB3eYiMiqkd2LdTo0doG303ri0Ed7KvsM+rzk9gVnoSFe68gPa8IFxLvNnCVRFRbvIJUS7yCREQV6fUC3v/5Kr4NTXhgv2tL/GGukvxNT0TNEq8gERE1MLlchiVju+FM0HC0aWlebb+nPv0NqTmFCNgegQOXUpFXVIqC4rIGrJSIHoZXkGqJV5CI6EH0egECgMPXtHh9a8QD+9qam8DKzAT/fLoTujhZor2DZcMUSdQMcZB2PWNAIqKa0usFFJbqcOByKt7ddemBfS1NlTi3wA+Hr6XBz1MDM5Wigaokah4YkOoZAxIRPSq9XkBkUja0OUVYsv8aUnMePGfSi/3a4MNnujdQdUTNQ01/f3OUIBFRA5HLZejVxhYAMLK7ExLuFGDDyThcSMyucpburWcSMayTA4Z7ahq6VKJmj1eQaolXkIiorpSU6TF/9yX8HJmCUl3lv5LferI9ernZopPGEs42ZlXuo0ynh1LB526IHoa32OoZAxIR1ZeHzdY9x68D3nqyA/SCgHd2XYJOL+BIVBpeHdQWgU91bMBKiRofBqR6xoBERPXpXHwWTt7IxOWkbByLzqiyj4lCVumKU/zK0Q1RHlGjxTFIRESNWB/3lujj3hIAkJxdiAOXUnDgshaRt7PFPlXdjiOiusEb1kRERs7FxgwzBrfD3oABOPuv4ejuYl1t3w2/xaGoVIcryTnQ6wWEJ2ShpEzfgNUSNQ28xVZLvMVGRFISBAG/XNEi9OYdXLydjcvJOdX29e+qwdoXvSGTyaDTCyjT66FWcn4lap44BqmeMSARkbHQ6wX8J+QG/hNyo9o+fd1bYtHfumD+7kuI0eZj5fjuGN3DiUGJmh0GpHrGgERExkYQBOyLTMHR6+nwbWuHRfuuPvD2Wh93WywZ2w37IlMwvLMDriTn4IW+bWBqwtBETRcDUj1jQCIiY5dXVIoDl1Ixf/flGm8zursT/vNCTygVcgiCAJlMVo8VEjU8BqR6xoBERI1Fzr1ShMbdQStLFews1HhlyznEZRQ8cBvXlmawMVNhx4x+sFDzgWdqOhiQ6hkDEhE1Vpn5xZiz4yJOxWYCANRKOYqruRU3obcrbCxMMLyzBqk5hXiqiwbmKgYmarwYkOoZAxIRNXZ6vYASnR5qpRw3Mwow9otTKCjRPXCbyb5u+NcoT+QUlkJjZdpAlRLVHQakesaARERNTZlOj9t3CzHs38cf2K+Puy0u3s7G+sm9MayTQ8MUR1RHGJDqGQMSETV1MWl5+OWyFv3b2+H5taFV9ln0f10Qm5GP8/FZ2Dy1b7Uv071XUga1UgGFnIO+SVoMSPWMAYmImpOiUh1mbb+AM3F3kF9cVm2/U/OGobWtOdJyi/DW9xfwnHdrDPfUYOiqY+jR2gZbX/VpwKqJKuO72IiIqM6Ymijw9ZTeKNPpkV9cBhOFHAM/Ooq790oN+g386Bi83WwRnnAXAHD2Vhbmj+yM3KIynIrNRFGpjvMsUaPAd7EREVGNKRVy2JirYKFWIjRoOLa96oO+Hi0N+vwZjv608pfr4s8/hic1SJ1Ej4u32GqJt9iIiAzFpudhd0QyNp66Ve20AQDQwaEF/LpooLFUY7inBq4tzVFcpoNOL3AKAap3HINUzxiQiIiqdye/GCqlHB/uj8LeyGQUlVYfmP5kaiLHvBGd8VtMBuxbqPHakHZo79CiAaql5qSmv7+N4hbbmjVr4O7uDlNTU/j4+CAsLKzavps3b4ZMJjP4mJoazsUhCAIWLVoEJycnmJmZwc/PDzduGL7EMSsrC5MmTYKVlRVsbGwwbdo05Ofn18vxERE1N3Yt1LA0NcFHz/XA9aUjcXP5KIS/5wcPe4tqtykq1eODn6/hWHQGfgxPwvv7rkKvF3Bdm4ucCmOdgPK/629n3QP/nU/1QfKAtHPnTgQGBmLx4sWIiIiAl5cX/P39kZ6eXu02VlZWSE1NFT8JCQkG6z/++GN8/vnnWLt2Lc6ePQsLCwv4+/ujqKhI7DNp0iRcvXoVhw8fxv79+/Hbb79hxowZ9XacRETNmUIug10LNY69PRSn5g3Df17oicjFT8PW3KTabU7FZqLtvw5ixOqTmL3zgtguCAKCr6Ri1aFoDPr4GDaeutUQh0DNjOS32Hx8fNCnTx988cUXAAC9Xg9XV1e8+eabmD9/fqX+mzdvxpw5c5CdnV3l/gRBgLOzM/75z3/i7bffBgDk5ORAo9Fg8+bNeOGFFxAVFYUuXbrg3Llz6N27NwAgODgYo0aNQlJSEpydnR9aN2+xERE9vuIyHbadSYR/N0fsvZiMr47dRF+Plgi5XvkfyWqlHG1btcCNtDyU6Q1/dd1aMYov1qUaaRS32EpKShAeHg4/Pz+xTS6Xw8/PD6GhVU9KBgD5+flwc3ODq6srxo4di6tXr4rrbt26Ba1Wa7BPa2tr+Pj4iPsMDQ2FjY2NGI4AwM/PD3K5HGfPnq3yO4uLi5Gbm2vwISKix6NWKvDKQA+42JjhjaHtcen9p7Hx5T7Y/qoPzFWG0wEUl+kRlZpbKRwBgNcHvyImLQ+CICDhTgFvu9FjkzQgZWZmQqfTQaPRGLRrNBpotdoqt+nUqRM2bdqEvXv3YuvWrdDr9ejfvz+SksofHf1zuwftU6vVwsHBcHp8pVKJli1bVvu9K1asgLW1tfhxdXV99AMmIqIH+vMqUP/29ri2ZARurRiFLa/0feh2uUVl2HomAf/8IRJDVh2HR9BBnI/PqrJveEIWnvz3cZz+42W9RFWRfAzSo/L19cXkyZPRs2dPDBkyBLt370arVq2wbt26ev3eoKAg5OTkiJ/bt2/X6/cREVF5YBrSsRVurRiFk+8Ow60Vo7BxSm+M7emMT573Muj7bWgCdl9IFpefWxuKPReSEZuej6LS+y/hfWfXJcRlFuAfX1d9x4AIkHgmbXt7eygUCqSlpRm0p6WlwdHRsUb7MDExQa9evRAbGwsA4nZpaWlwcnIy2GfPnj3FPhUHgZeVlSErK6va71Wr1VCr1TWqiYiI6pZMJoNrS3MAwHBPDYZ7lt8l8OuiQfLdQjy39jTuleiglMtgplIgr6j8dShzdl4EUD5+aUp/d/i2tUNcRoG438z8YmTmF6Oz4/2xKDn3SmGuVsBEcf8agl4vQM73yDUrkl5BUqlU8Pb2RkhIiNim1+sREhICX1/fGu1Dp9Ph8uXLYhjy8PCAo6OjwT5zc3Nx9uxZcZ++vr7Izs5GeHi42Ofo0aPQ6/Xw8eF7goiIGgtrMxN0cbbCxUVP48Q7Q3Hs7aG4/L4/XhvS1qBfcZke63+Lw9TN5wzae394BCNWn8STnxzHu7sicSU5B32WHcE/f4hEblEp8opKcTMjHz2X/IrPDsc05KGRxCR/im3nzp2YMmUK1q1bh759+2L16tX44YcfcP36dWg0GkyePBkuLi5YsWIFAGDJkiXo168f2rdvj+zsbKxatQp79uxBeHg4unTpAgD46KOPsHLlSmzZsgUeHh5YuHAhLl26hGvXrolzJo0cORJpaWlYu3YtSktLMXXqVPTu3Rvbt2+vUd18io2IyLjp9QKORKXB3d4Cnx2OwS9Xqh5j+iCtbc3g1doGBy6nAgDiV46u6zKpgTWal9VOmDABGRkZWLRoEbRaLXr27Ing4GBxkHViYiLk8vsXuu7evYvp06dDq9XC1tYW3t7eOH36tBiOAODdd99FQUEBZsyYgezsbAwcOBDBwcEGE0pu27YNs2bNwvDhwyGXyzF+/Hh8/vnnDXfgRERUr+RyGZ7uWj5s4vOJvXArswB5RaXYeiYRMWl5uJqSC7kMqOKhOFHS3ULxdh0AzP/fJQQMay/e7qOmS/IrSI0VryARETVu4QlZsG+hRqlOjzk7L+JKcs2nbzk1bxjScovQUWMJS1MTXNfmQqUon6eJjBvfxVbPGJCIiJqWeyVl+PM34vrf4mBrboI1x28iI6/4gduplHKUlOlhopBh26v9kJJdiKS79zCimxPatbLgBJZGhgGpnjEgERE1fYUlOqw+EoPfb2bCytQEp2/eeaTtrc1MsP/NgTW+JZdVUILI29kY0rEVn5qrJwxI9YwBiYio+cnIK8a6EzeRXViKvReTUaqr2a/QF/u1QWtbc2TkFWNUd0d4u7XEufgsWJoqDaYY+L//nsSV5Fyseq4HTBRy5BeX4cV+bvV1OM0SA1I9Y0AiImreBEHAtdRctLJUI/TmHcSk5WHNsZvopLFEF2cr/PSXSSsrGtfLRZzU8j8v9IRXaxs4Wpui88JgAEBvN1ucT7gLADj57jAOCq9DDEj1jAGJiIgqKigug7lKgRKdHhcSs/HOrkjczip8rH32a9sShaV6rH/JGxor00rrz8dnYe2Jm1j4f13gZmfxWN/VHDAg1TMGJCIiehi9XkB+SRlitHlIzi7Ek50d8J8jN7Dz3G3kFZc9fAd/4dXaGnsCBlQa9N3uXweh0wvo1cYGP70xAIIg4N+/RsO+hRpTB3jU5eE0CQxI9YwBiYiIaiu3qBTanCL8clmLz4482gzdL/Zrg2htHl7u74GBHezh9cGv4rojgUNQWKLD3744BQC4vnQETE0UVe5HpxegaIYDwRmQ6hkDEhER1RVBEMQrQ1GpuYhJy8NvMZm4nJyNmLT8Wu/30JzB6ORoWal9/6UUzNp+AZ/+3Qvjnmhd6/03RgxI9YwBiYiI6ltxmQ6Xk3LQwlSJ2d9fRHRa3iNt/8oAD3g6WcLD3gKZ+SV4ws0GmXklGPX5SbHPrRWjqp2raXdEEhRyGcb2dHms4zAmjeZVI0RERFQ1tVKB3u4tAQC/zB4EoPz1Jzcz8pGZX4xvQxNwOTmn2u03/X6rUpuHveFA7sPX0vBUFw0W7b2KfZEpcLYxw5eTnkBLcxUCf4gEAAzr7AArU5O6OqxGgVeQaolXkIiIyBjkFZVCAJCZVwwP+/KZu9PzijB9y3lEJlUfnjzsLXArs6Da9cue7YYFP10BAHzyvBee7OwAazMTXEvNRRcnq0Y7kSVvsdUzBiQiIjJmJWV6XNfmYndEMvKLy7ArPAkAoFLI8cawdujt1hIvbjxb4/31aG2NMV7O+PBAFOaP7IznvFvj7R8j8aKPG/y6aMR+0do85BeXwtutZZ0fU11gQKpnDEhERNTY/PXJNZ1ewHt7LuP7sNuPvd/lz3bHP3zaoEynR/sFvwAAQoOehJO12WPvu64xINUzBiQiImoqBEGAIACrQ24gLiMf/3y6E+bsuIDIpBy0tFAhq6CkRvvp69ESYbeyxJ8X/6188kqlXIbz8XfR16MlVEp5fR7KQzEg1TMGJCIiasp0egH5RWWwNjfB/8KTsHDvFZiZKDCss4N4u+5R+Xi0xPtjuqKFWglHa1OYKMrDUm5RKW6k5eOnC0no62GHiIS7eMe/EyzUdf8sGQNSPWNAIiKi5upuQQl+upCMwlId1Eo5PjwQVav9uNmZY6yXM749k4Dse6UG6/7h0wbLn+1eF+UaYECqZwxIRERE9xWW6BB8NRUWKiUuJ+dg3BOt8dOFZHwecgMAYGmqRF5RzV+vYt9CjfPv+dV5nQxI9YwBiYiI6OES7hQgNacI/dra4fTNTHwUHI3I29k12nb/mwPRzcW6TuvhRJFEREQkOTc7C7jZlU9O2b+dPfYG2KO4TIfiMj1kAE7fvIPwhLuY69cRpXo9Vv5yHdvPJsLOQoWU7MI6D0g1xStItcQrSERERPUjI68YLdRKmKmqftHu4+AVJCIiImqUWlmqpS4B0k5GQERERGSEGJCIiIiIKmBAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiIiIqAIGJCIiIqIKlFIX0FgJggAAyM3NlbgSIiIiqqk/f2//+Xu8OgxItZSXlwcAcHV1lbgSIiIielR5eXmwtraudr1MeFiEoirp9XqkpKTA0tISMpmszvabm5sLV1dX3L59G1ZWVnW2X6qM57ph8Dw3DJ7nhsHz3HDq61wLgoC8vDw4OztDLq9+pBGvINWSXC5H69at623/VlZW/MPXQHiuGwbPc8PgeW4YPM8Npz7O9YOuHP2Jg7SJiIiIKmBAIiIiIqqAAcnIqNVqLF68GGq1WupSmjye64bB89wweJ4bBs9zw5H6XHOQNhEREVEFvIJEREREVAEDEhEREVEFDEhEREREFTAgEREREVXAgGRk1qxZA3d3d5iamsLHxwdhYWFSl9RorFixAn369IGlpSUcHBzwzDPPIDo62qBPUVERAgICYGdnhxYtWmD8+PFIS0sz6JOYmIjRo0fD3NwcDg4OeOedd1BWVtaQh9KorFy5EjKZDHPmzBHbeJ7rTnJyMl588UXY2dnBzMwM3bt3x/nz58X1giBg0aJFcHJygpmZGfz8/HDjxg2DfWRlZWHSpEmwsrKCjY0Npk2bhvz8/IY+FKOl0+mwcOFCeHh4wMzMDO3atcPSpUsN3tXF81w7v/32G/72t7/B2dkZMpkMe/bsMVhfV+f10qVLGDRoEExNTeHq6oqPP/748YsXyGjs2LFDUKlUwqZNm4SrV68K06dPF2xsbIS0tDSpS2sU/P39hW+++Ua4cuWKcPHiRWHUqFFCmzZthPz8fLHP66+/Lri6ugohISHC+fPnhX79+gn9+/cX15eVlQndunUT/Pz8hAsXLggHDx4U7O3thaCgICkOyeiFhYUJ7u7uQo8ePYTZs2eL7TzPdSMrK0twc3MTXn75ZeHs2bNCXFyccOjQISE2Nlbss3LlSsHa2lrYs2ePEBkZKYwZM0bw8PAQCgsLxT4jRowQvLy8hDNnzggnT54U2rdvL0ycOFGKQzJKy5YtE+zs7IT9+/cLt27dEn788UehRYsWwn/+8x+xD89z7Rw8eFBYsGCBsHv3bgGA8NNPPxmsr4vzmpOTI2g0GmHSpEnClStXhO+//14wMzMT1q1b91i1MyAZkb59+woBAQHisk6nE5ydnYUVK1ZIWFXjlZ6eLgAQTpw4IQiCIGRnZwsmJibCjz/+KPaJiooSAAihoaGCIJT/YZbL5YJWqxX7fPXVV4KVlZVQXFzcsAdg5PLy8oQOHToIhw8fFoYMGSIGJJ7nujNv3jxh4MCB1a7X6/WCo6OjsGrVKrEtOztbUKvVwvfffy8IgiBcu3ZNACCcO3dO7PPLL78IMplMSE5Orr/iG5HRo0cLr7zyikHbuHHjhEmTJgmCwPNcVyoGpLo6r19++aVga2tr8HfHvHnzhE6dOj1WvbzFZiRKSkoQHh4OPz8/sU0ul8PPzw+hoaESVtZ45eTkAABatmwJAAgPD0dpaanBOe7cuTPatGkjnuPQ0FB0794dGo1G7OPv74/c3FxcvXq1Aas3fgEBARg9erTB+QR4nuvSvn370Lt3bzz//PNwcHBAr169sGHDBnH9rVu3oNVqDc61tbU1fHx8DM61jY0NevfuLfbx8/ODXC7H2bNnG+5gjFj//v0REhKCmJgYAEBkZCROnTqFkSNHAuB5ri91dV5DQ0MxePBgqFQqsY+/vz+io6Nx9+7dWtfHl9UaiczMTOh0OoNfGACg0Whw/fp1iapqvPR6PebMmYMBAwagW7duAACtVguVSgUbGxuDvhqNBlqtVuxT1X+DP9dRuR07diAiIgLnzp2rtI7nue7ExcXhq6++QmBgIP71r3/h3LlzeOutt6BSqTBlyhTxXFV1Lv96rh0cHAzWK5VKtGzZkuf6D/Pnz0dubi46d+4MhUIBnU6HZcuWYdKkSQDA81xP6uq8arVaeHh4VNrHn+tsbW1rVR8DEjVJAQEBuHLlCk6dOiV1KU3O7du3MXv2bBw+fBimpqZSl9Ok6fV69O7dG8uXLwcA9OrVC1euXMHatWsxZcoUiatrOn744Qds27YN27dvR9euXXHx4kXMmTMHzs7OPM/NGG+xGQl7e3soFIpKT/qkpaXB0dFRoqoap1mzZmH//v04duwYWrduLbY7OjqipKQE2dnZBv3/eo4dHR2r/G/w5zoqv4WWnp6OJ554AkqlEkqlEidOnMDnn38OpVIJjUbD81xHnJyc0KVLF4M2T09PJCYmArh/rh7094ajoyPS09MN1peVlSErK4vn+g/vvPMO5s+fjxdeeAHdu3fHSy+9hLlz52LFihUAeJ7rS12d1/r6+4QByUioVCp4e3sjJCREbNPr9QgJCYGvr6+ElTUegiBg1qxZ+Omnn3D06NFKl1y9vb1hYmJicI6jo6ORmJgonmNfX19cvnzZ4A/k4cOHYWVlVekXVXM1fPhwXL58GRcvXhQ/vXv3xqRJk8SfeZ7rxoABAypNVRETEwM3NzcAgIeHBxwdHQ3OdW5uLs6ePWtwrrOzsxEeHi72OXr0KPR6PXx8fBrgKIzfvXv3IJcb/jpUKBTQ6/UAeJ7rS12dV19fX/z2228oLS0V+xw+fBidOnWq9e01AHzM35js2LFDUKvVwubNm4Vr164JM2bMEGxsbAye9KHqzZw5U7C2thaOHz8upKamip979+6JfV5//XWhTZs2wtGjR4Xz588Lvr6+gq+vr7j+z8fPn376aeHixYtCcHCw0KpVKz5+/hB/fYpNEHie60pYWJigVCqFZcuWCTdu3BC2bdsmmJubC1u3bhX7rFy5UrCxsRH27t0rXLp0SRg7dmyVj0n36tVLOHv2rHDq1CmhQ4cOzf7x87+aMmWK4OLiIj7mv3v3bsHe3l549913xT48z7WTl5cnXLhwQbhw4YIAQPj000+FCxcuCAkJCYIg1M15zc7OFjQajfDSSy8JV65cEXbs2CGYm5vzMf+m5r///a/Qpk0bQaVSCX379hXOnDkjdUmNBoAqP998843Yp7CwUHjjjTcEW1tbwdzcXHj22WeF1NRUg/3Ex8cLI0eOFMzMzAR7e3vhn//8p1BaWtrAR9O4VAxIPM915+effxa6desmqNVqoXPnzsL69esN1uv1emHhwoWCRqMR1Gq1MHz4cCE6Otqgz507d4SJEycKLVq0EKysrISpU6cKeXl5DXkYRi03N1eYPXu20KZNG8HU1FRo27atsGDBAoPHxnmea+fYsWNV/r08ZcoUQRDq7rxGRkYKAwcOFNRqteDi4iKsXLnysWuXCcJfpgolIiIiIo5BIiIiIqqIAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiqiMymQx79uyRugwiqgMMSETUJLz88suQyWSVPiNGjJC6NCJqhJRSF0BEVFdGjBiBb775xqBNrVZLVA0RNWa8gkRETYZarYajo6PBx9bWFkD57a+vvvoKI0eOhJmZGdq2bYtdu3YZbH/58mU8+eSTMDMzg52dHWbMmIH8/HyDPps2bULXrl2hVqvh5OSEWbNmGazPzMzEs88+C3Nzc3To0AH79u2r34MmonrBgEREzcbChQsxfvx4REZGYtKkSXjhhRcQFRUFACgoKIC/vz9sbW1x7tw5/Pjjjzhy5IhBAPrqq68QEBCAGTNm4PLly9i3bx/at29v8B0ffPAB/v73v+PSpUsYNWoUJk2ahKysrAY9TiKqAwIRURMwZcoUQaFQCBYWFgafZcuWCYIgCACE119/3WAbHx8fYebMmYIgCML69esFW1tbIT8/X1x/4MABQS6XC1qtVhAEQXB2dhYWLFhQbQ0AhPfee09czs/PFwAIv/zyS50dJxE1DI5BIqImY9iwYfjqq68M2lq2bCn+7Ovra7DO19cXFy9eBABERUXBy8sLFhYW4voBAwZAr9cjOjoaMpkMKSkpGD58+ANr6NGjh/izhYUFrKyskJ6eXttDIiKJMCARUZNhYWFR6ZZXXTEzM6tRPxMTE4NlmUwGvV5fHyURUT3iGCQiajbOnDlTadnT0xMA4OnpicjISBQUFIjrf//9d8jlcnTq1AmWlpZwd3dHSEhIg9ZMRNLgFSQiajKKi4uh1WoN2pRKJezt7QEAP/74I3r37o2BAwdi27ZtCAsLw8aNGwEAkyZNwuLFizFlyhS8//77yMjIwJtvvomXXnoJGo0GAPD+++/j9ddfh4ODA0aOHIm8vDz8/vvvePPNNxv2QImo3jEgEVGTERwcDCcnJ4O2Tp064fr16wDKnzDbsWMH3njjDTg5OeH7779Hly5dAADm5uY4dOgQZs+ejT59+sDc3Bzjx4/Hp59+Ku5rypQpKCoqwmeffYa3334b9vb2eO655xruAImowcgEQRCkLoKIqL7JZDL89NNPeOaZZ6QuhYgaAY5BIiIiIqqAAYmIiIioAo5BIqJmgaMJiOhR8AoSERERUQUMSEREREQVMCARERERVcCARERERFQBAxIRERFRBQxIRERERBUwIBERERFVwIBEREREVMH/AypTThwcQSYcAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss['losses'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"Ліктя\" тут на жаль немає("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
